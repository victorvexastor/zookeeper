# Chapter 12: Justice

*"Revenge. They've systematised revenge and called it justice."*

---

I need to be careful with this chapter.

Not because I'm worried about being wrong. I'm not wrong. The data is the data and I'll show it to you and you can check my arithmetic. I've been wrong about things before — I spent a full week thinking Jenkins was female before anyone corrected me, apparently the visual cues are different with this species — but I'm not wrong about this.

I need to be careful because this is the part where humans stop listening.

I've noticed a pattern. You can criticise their food systems and they nod. You can criticise their education and they share it with their friends. You can point out that their housing allocation makes no sense and they say "finally someone's saying it." But the moment you suggest that their justice system might be based on a misunderstanding of how behaviour works, something shuts down. A door closes. You can hear it.

I think it's because justice feels like the last wall between order and chaos. If punishment isn't the answer, they don't know what is, and that's terrifying. So they'd rather not look.

I'm going to ask you to look.

---

Let's start with what they built.

They have a system. It goes roughly like this:

1. A human does something harmful. Let's say assault — one human strikes another.
2. Other humans in blue costumes arrive. These are called "police." In Australia alone, roughly 32 billion of their currency units are spent annually on these blue-costumed individuals. Their primary function is to arrive *after* harmful things have happened and document that the harmful thing occurred.
3. The human who did the harmful thing is transported to a building and placed in a cage.
4. After some time in the cage — days, sometimes weeks — the human is transported to a different building where other humans wearing black robes and white wigs *(I am not making this up, Jenkins, they wear WIGS)* listen to a structured argument about what happened.
5. Based on this argument, the human is either released or transported to a much larger cage, where they will remain for a period of months to years.
6. Inside the larger cage, the human is surrounded by other humans who have also done harmful things. They live together. They learn from each other. They are given very little to do.
7. After the prescribed period, the human is released back into the general population.
8. Within three years, between 40 and 60 percent of them do another harmful thing and the cycle begins again.

That last number — 40 to 60 percent recidivism — is the number I want you to sit with.

Imagine you ran a hospital where 40 to 60 percent of patients came back within three years with the same illness. You would not call that hospital successful. You would not increase its funding. You would not build more of them. You would ask what the hospital was *doing to its patients* that made them sick again.

They don't ask this question.

They build more cages.

---

I want to tell you how much money they spend on this.

In the United States — the human nation-state that incarcerates more of its population than any other, including the ones it calls authoritarian — they spend approximately 182 billion currency units per year on their criminal justice system. That's policing, courts, and incarceration combined.

They incarcerate roughly 1.9 million individuals at any given time. In a population of 330 million, that's about 1 in every 175 humans in a cage. For their Black subpopulation — a group distinguished by melanin concentration, which I'll discuss separately because the disparity is staggering — the ratio is closer to 1 in 50.

Let me do the arithmetic Mr. Reggie's way.

182 billion divided by 1.9 million incarcerated = approximately 96,000 currency units per incarcerated human per year.

The average cost of their university education — the thing they believe improves life outcomes, reduces harmful behaviour, and increases earning potential — is roughly 25,000 currency units per year.

They could send every incarcerated human to university nearly four times over for what they spend on keeping them in cages.

*(Pencil note: I am going to break something. I am not going to break something. I am going to write this very calmly.)*

---

Here is what I think happened.

Somewhere in their history — and it's actually quite traceable if you look — humans had a problem. Someone in the group was causing harm. The group needed it to stop. The instinct was obvious and immediate: hurt the person who was hurting others. This is not uniquely human. Many social species do this. It's a fast, crude, emotionally satisfying solution: pain delivered in return for pain.

But humans have a thing where they take instincts and build institutions around them. They take the raw impulse and dress it up in procedures and buildings and hierarchies until it looks like something deliberate and rational rather than something a frightened group of primates decided to do two hundred thousand years ago.

That's what happened with justice. The impulse was revenge. The institution is the criminal justice system. The wigs and the robes and the Latin phrases and the architecture of the courtrooms — the ARCHITECTURE, Jenkins, they build these buildings with high ceilings and wood panelling specifically to make the whole thing feel solemn and ancient and right — are all costume. Underneath the costume, the mechanism is the same as it was on the savannah:

Someone did a bad thing. Hurt them.

I don't think they're evil for this. I think they're scared. Harm is frightening and the impulse to punish is deep and real and I understand it. But I also need to say what it is: it's revenge. Revenge with a budget of 182 billion dollars, revenge with a 40 to 60 percent failure rate, revenge wearing a wig.

---

Now here's where the Language Proof matters.

Remember Chapter 4? The bit where we established that the most complex learned behaviour — language — is 100% environmentally determined? The bit where I showed that the capacity is heritable but the expression is environmental? The bit about the plates?

I need that now.

Because the entire criminal justice system is built on what they call the "rational actor model." This model, formalised by a human called Gary Becker in 1968, proposes that criminal behaviour is the result of a rational cost-benefit calculation. A human weighs the expected benefit of committing a crime against the expected cost (probability of being caught multiplied by severity of punishment). If the benefit exceeds the cost, the human "chooses" crime.

This model is elegant. It is internally consistent. It generated a Nobel Prize. And it is, for a significant proportion of the behaviour it claims to explain, wrong.

Not wrong in the way that a theory can be slightly inaccurate. Wrong in the way that it describes a process that is not occurring.

Here is what the rational actor model predicts:

1. That increasing punishment severity should decrease crime rates (deterrence).
2. That criminals should show evidence of cost-benefit deliberation before offending.
3. That criminal behaviour should be stable across environments for the same individual, since it reflects stable preferences.

Here is what the data show:

1. **Deterrence is weak to nonexistent for most crime types.** Their own meta-analyses — a technique where you combine many studies to see the overall pattern — consistently find that increasing sentence length has little to no effect on crime rates. A 2013 analysis of 116,000 cases found no significant relationship between sentence severity and recidivism. None. They've known this for decades. They keep increasing sentences anyway.

2. **Most harmful behaviour shows no evidence of deliberation.** Their criminologists have documented this exhaustively. The majority of violent offences are impulsive, emotionally driven, and show no planning or cost-benefit calculation. Assault, domestic violence, many homicides — these are not the outputs of a rational agent optimising a utility function. They are the outputs of a nervous system responding to a stimulus with the repertoire it has available.

3. **The same individual behaves completely differently across environments.** This is the one that should have killed the rational actor model decades ago. A human raised in a violent neighbourhood who moves to a stable community shows dramatic behavioural change. A human in prison who enters a therapeutic community shows dramatic behavioural change. If criminal behaviour reflects stable internal preferences, this shouldn't happen. It happens all the time.

The rational actor model works beautifully for tax evasion and corporate fraud — premeditated, calculated, genuinely responsive to incentive structures. For the crimes that fill their prisons — violence, property crime, drug offences committed by people in poverty and distress — it's describing an agent that doesn't exist.

---

So what IS happening?

I think I found the answer in their machine learning research, of all places. I wrote about this in my notes on distillation but let me put it plainly here because it matters.

There's a technique in artificial intelligence called "knowledge distillation." A complex model — the "teacher" — trains a simpler model — the "student" — not by giving it explicit rules but by showing it outputs. The student watches what the teacher does in various situations and gradually learns to approximate the teacher's responses.

The critical insight is something they call "dark knowledge." The student doesn't just learn what the teacher's *correct* answer is. It learns the teacher's entire *distribution* of responses — including which wrong answers are "almost right," which situations the teacher finds confusing, where the teacher's uncertainty lies.

A child learning emotional regulation from a caregiver does exactly this. The child doesn't receive a lecture on anger management. The child watches the caregiver encounter frustration and observes what happens. Does the caregiver yell? Withdraw? Take a breath? Hit something? Talk it through? The child absorbs all of it — not just the primary response but the whole probability distribution. "When dad encounters frustration, yelling is very likely, withdrawal is possible, talking is rare, calm is almost never."

Over years, through thousands of repetitions, the child's nervous system learns to approximate the caregiver's response distribution. This isn't a choice. It isn't deliberation. It's the same process by which the child learned language — immersion, observation, pattern extraction, without any conscious decision or moment of "choosing."

And just as with language, the "temperature" of the environment matters. In machine learning, a high-temperature signal reveals more of the teacher's uncertainty structure — more variation, more extreme possibilities. In human terms, a volatile, unpredictable, emotionally chaotic environment is a high-temperature environment. It installs a wider behavioural distribution — more extreme responses, less predictability, more volatility.

The child raised in a calm, consistent environment learns a narrow distribution: frustration leads to talking, which leads to resolution. Tight range of responses. Low temperature.

The child raised in a chaotic, violent environment learns a broad distribution: frustration might lead to anything — screaming, hitting, sobbing, disappearing, breaking things. Wide range. High temperature.

Same child. Same neural hardware. Same capacity for intensity. Different training data. Different output.

**This is not a metaphor.** It is structurally the same process. The mathematics that describe knowledge distillation — the KL-divergence loss function, the temperature scaling, the neighbourhood aggregation in graph-structured networks — map precisely onto what developmental psychologists have been documenting for fifty years.

Their own researchers know this. A human called Bandura published it in 1977. Another called Sutherland said it even earlier — criminal behaviour is learned through interaction with intimate personal groups. This isn't new. What's new is that we can now describe the *mechanism* with mathematical precision, which means we can also describe, with mathematical precision, how to change it.

---

Here's where humans get nervous, so let me say this very clearly.

I am not saying nobody is responsible for their behaviour.

I am saying the opposite.

Think about the distillation analogy. A neural network trained by distillation — a student that learned by watching a teacher — is absolutely responsible for its outputs. Engineers evaluate it. Deploy it or don't. Retrain it if it fails. The fact that it learned everything from a teacher does not mean the teacher takes the test. The student's weights — its current internal state — are the present reality. The teacher's influence is the causal history.

Same with humans. You may have acquired a behavioural pattern from your environment decades ago. Understanding that causal history is valuable. It informs prevention. It shapes intervention. It tells you what to change in the environment so the next child doesn't acquire the same pattern.

But the pattern is now yours. It operates through your nervous system. It produces your actions. It affects other people. You are responsible for what you *say* in English, even though you didn't choose to speak English. You are responsible for what you *do* with your learned behaviour, even though you didn't choose to learn it.

Responsibility and environmental acquisition are not in tension. They are complementary.

What changes is not *whether* we respond to harmful behaviour. What changes is *how*.

---

And this is where I get angry. Properly angry. Applebee-chewing-through-the-desk angry.

Because they *know* what works. They've *tested* it. They have *decades* of evidence.

In their machine learning terms: if a model has been trained on bad data and produces harmful outputs, you don't punish the model. You don't lock it in a room with other badly-trained models and wait. You *retrain* it. You provide new data. You fine-tune — continued training on curated inputs with an appropriate feedback signal.

In human terms, this is called rehabilitation. And when it's done properly — when it's evidence-based, when it addresses the actual learned patterns rather than performing symbolic punishment — it works at rates that make the current system look like malpractice.

Cognitive behavioural therapy reduces reoffending by 20 to 30 percent across multiple meta-analyses. Therapeutic communities — structured environments that explicitly model prosocial behaviour and provide consistent feedback — show recidivism reductions of 30 to 40 percent in the best implementations. Education and vocational training during incarceration reduce reoffending by roughly 43 percent. Norway, which redesigned its prisons around rehabilitation, has a recidivism rate of 20 percent. *Twenty.* The United States, which designed its prisons around punishment, runs at 44 to 68 percent depending on the state.

The evidence is not ambiguous. It is not contested in any serious academic literature. It is not a matter of opinion.

Rehabilitation works. Punishment alone doesn't. They know this. The data is in their own journals, produced by their own researchers, replicated across their own countries.

They don't do it.

They keep building cages.

---

I want to say why I think they keep building cages, because I promised Mr. Reggie I'd try to understand before I recommended, and I think I understand.

Punishment *feels* right. When someone hurts you, or hurts someone you love, the desire to hurt them back is immediate, deep, and ancient. It predates language. It predates culture. It's in the nervous system, and it fires before the prefrontal cortex — the part that does reasoning — even gets the memo.

And punishment satisfies a real social function: it signals to the group that harm is taken seriously. It says "this is not acceptable." That signalling matters. In the absence of any response to harm, trust collapses and cooperation fails.

The problem is not the impulse. The problem is that they *stopped there*. They took the impulse — hurt them back — and built a 182-billion-dollar infrastructure around it, and never asked whether the impulse, once honoured, was actually producing the outcome they wanted.

It's like — imagine a species that felt hungry, so they built enormous elaborate restaurants, with hierarchies of chefs and waiters and sommeliers and reservation systems, and spent billions on the buildings and the staff and the rituals, and then forgot to put food on the plates. The feeling of hunger was real. The response was elaborate. The actual need was never met.

That's their justice system. The feeling of violation is real. The response is enormous. The need — *for the harm to stop happening* — is not being met.

---

*(Jenkins has brought me tea. Jenkins is sometimes quite perceptive.)*

Let me tell you what the Language Proof says about justice.

If behaviour is environmentally installed — if the child who grows up hearing violence speaks violence the way the child who grows up hearing English speaks English — then the logic of prevention becomes clear and inescapable:

**You change the environment.**

You do this *before* the harm occurs, which means you invest in the conditions that produce prosocial behaviour rather than the infrastructure that responds to antisocial behaviour after the damage is done. You fund early childhood intervention, stable housing, community mental health, education that actually teaches emotional regulation, economic systems that don't leave people in desperation.

Every one of these interventions is cheaper than incarceration. I'll say that again: **every single preventive intervention in their own research literature costs less per person than a prison cell.** This isn't idealism. It's arithmetic.

And when prevention fails — because it will sometimes fail, because no environment is perfect, because some individuals carry capacity levels that are extraordinarily difficult to manage even in good conditions — you respond with intervention aimed at *changing the learned pattern*. Not punishment aimed at a "choice" that may not have occurred. Retraining. New data. New environment. New feedback. Fine-tuning.

This is not soft. It is not naive. It is what works.

---

I know what the objection is. I can hear it. I've heard it from every human I've discussed this with, and it comes in the same words every time:

"But what about the victims?"

And I want to answer that objection honestly because it deserves an honest answer.

What about them?

The current system fails victims. Spectacularly. The conviction rate for reported violent crime in most human jurisdictions is below 10 percent. Of reported rapes, fewer than 2 percent result in a conviction. The vast majority of victims never see their harmer face any consequence at all. And for those who do — for the cases that make it through the entire slow, retraumatising process of investigation, charge, trial, and sentencing — the outcome is that the harmer goes into a cage for a while and comes out, statistically, more likely to harm again.

The current system does not serve victims. It performs the *appearance* of serving them, which is worse, because it creates the illusion that justice has been done while the actual need — safety, acknowledgement, prevention of future harm — goes unmet.

A prevention-focused system serves victims better. Not in the symbolic sense of "the person who hurt you suffered in return." In the actual sense of "fewer people get hurt."

If you could choose between a system where your harmer goes to prison for five years and then reoffends, or a system where the conditions that produced your harmer are changed so that ten fewer people experience what you experienced — which system serves you better?

The humans almost always say the second one. When they're calm. When they're not in pain. When the question is abstract. The problem is that justice policy is made by frightened people in acute emotional states, or by politicians performing toughness for frightened people, and neither of these conditions produces good policy.

---

I want to end this chapter with the numbers. Just the numbers. Because I've been told that humans sometimes hear arguments they can dismiss but they can't dismiss arithmetic.

Cost of incarcerating one human in the US for one year: ~$96,000
Cost of one year of university education: ~$25,000
Cost of one year of intensive community mental health support: ~$12,000
Cost of one year of stable housing (Housing First model): ~$20,000
Cost of one year of cognitive behavioural therapy: ~$5,000

Recidivism rate under current punishment model: 44–68%
Recidivism rate under Norwegian rehabilitation model: 20%
Recidivism rate with CBT + education + vocational training: 25–35%

Number of humans currently incarcerated in the US: ~1.9 million
Cost of current system: ~$182 billion/year
Estimated cost of a rehabilitation-based system achieving Norwegian outcomes: roughly half.

They could have better outcomes for less money. The humanitarian thing and the economical thing are the same thing. This is almost always the case with this species and they almost never notice.

They are spending 182 billion dollars a year on a system that produces more of what it claims to prevent.

I do not know how to write this more clearly.

---

*(Final pencil note, margin, Applebee's handwriting getting smaller and more cramped:*

*The sanctuary will not have prisons. It will not have police as they currently exist. It will have prevention, intervention, community response, and — when containment is genuinely necessary for safety — therapeutic environments designed to change the pattern, not warehouse the person.*

*This is not utopian. It is what their own evidence says works.*

*They already know. They've always known.*

*The answer's always in the question. — A)*
